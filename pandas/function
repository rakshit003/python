************ Reading data as date from external file ************************

Automatic
It should be noted that Pandas integrates powerful date parsers such that many different kinds of dates can be parsed automatically. 
Thus, you usually just need to set the parse_date parameter.

df = pd.read_csv("dates_text.csv", parse_dates=["date"])

if date values are spread across multiple columns then read like this

**data**
y,m,d,category,balance
2022,01,01,A,100
2022,02,02,B,200
2022,03,12,C,300

df_cols = pd.read_csv("dates_text_cols.csv", parse_dates={"date": ["y", "m", "d"]})

Also we can only read specific columns in data frame by using 'usecols' option like below:
df = pd.read_csv("/content/melb_housing.csv",usecols = ["Suburb", "Address", "Date","Distance", "Price"])

**customized date parser

pd.read_csv("custom_dt_fmt.csv", parse_dates=["date"], date_parser=lambda x: datetime.strptime(x, "%b_%d_%Y"))
The tricky thing here is to define the proper date format in the strptime method.

****************processing dates in pandas*********

>>> pd.to_datetime("Jan 01, 2022") #to_datetime function converts any date string to pandas datetime object
Timestamp('2022-01-01 00:00:00')
>>> pd.to_datetime(["01/01/2022", "01/02/2022", "01/03/2022"])
DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03'], dtype='datetime64[ns]', freq=None)
>>> pd.to_datetime(pd.Series(["01/01/2022", "01/02/2022", "01/03/2022"]))

**creating date range in pandas

pd.date_range(start="12/01/2022", end="12/07/2022")
DatetimeIndex(['2022-12-01', '2022-12-02', '2022-12-03', '2022-12-04',
               '2022-12-05', '2022-12-06', '2022-12-07'],

**sepeating date from time using dt class
>>> df["date"] = df["timestamp"].dt.date
>>> df["time"] = df["timestamp"].dt.time

or dt.month, dt.year, dt.weekday -- all are possible


**************iterating over dataframes**************
for index, row in df.iterrows():
  print(row["firstname"])
  
**********indexing*******************
iloc is conceptually simpler than loc because it ignores the dataset's indices. 
When we use iloc we treat the dataset like a big matrix (a list of lists), one that we have to index into by position. 
loc, by contrast, uses the information in the indices to do its work. 


***Filtering

reviews.loc[(reviews.country == 'Italy') & (reviews.points >= 90)]

Filtering multiple values
#if you have a lot of values to filter on a column the use isin

reviews.loc[reviews.country.isin(['Italy', 'France'])]
reviews.loc[reviews.price.notnull()]
reviews.loc[reviews.price.isnull()]

****************Assigning values************************

reviews['critic'] = 'everyone' #constant value
reviews['index_backwards'] = range(len(reviews), 0, -1) #range

*****apply and map functions**********
Maps allow us to transform data in a DataFrame or Series one value at a time for an entire column.

If we had called reviews.apply() with axis='index', 
then instead of passing a function to transform each row, 
we would need to give a function to transform each column.

Note that map() and apply() return new, transformed Series and DataFrames, respectively. 
They don't modify the original data they're called on. 
If we look at the first row of reviews, we can see that it still has its original points value.

def remean_points(row):
    row.points = row.points - review_points_mean
    return row

reviews.apply(remean_points, axis='columns')

review_points_mean = reviews.points.mean()
reviews.points.map(lambda p: p - review_points_mean)

*********group by operator*************
groupby() created a group of reviews which allotted the same point values to the given wines.
Then, for each of these groups, we grabbed the points() column and counted how many times it appeared. 
value_counts() is just a shortcut to this groupby() operation.

We can use any of the summary functions we've used before with this data. 
For example, to get the cheapest wine in each point value category, we can do the following:
reviews.groupby('points').price.min()

You can think of each group we generate as being a slice of our DataFrame containing only data with values that match. 

**apply mehtod on group by
This DataFrame is accessible to us directly using the apply() method, and we can then manipulate the data in any way we see fit. 

For example, here's one way of selecting the name of the first wine reviewed from each winery in the dataset:
reviews.groupby('winery').apply(lambda df: df.title.iloc[0]) #instead of a row entire data frame slice of the group is passed

df_rank=df.groupby('claim_num').apply(lambda df:  df.sort_values('change_date',ascending=False).iloc[0])


**group by with agg**
Another groupby() method worth mentioning is agg(), which lets you run a bunch of different functions on your DataFrame simultaneously. 
For example, we can generate a simple statistical summary of the dataset as follows:
reviews.groupby(['country']).price.agg([len, min, max])

group columns are created as multi index, inorder to reset them yo normal columns use below command
countries_reviewed.reset_index()


/**********merging two data frame **********/

pd.merge(df1,df2,on='col_name', how ='inner')

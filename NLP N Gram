def sentence_to_trigram(tokenized_sentence):
    """
    Prints all trigrams in the given tokenized sentence.
    
    Args:
        tokenized_sentence: The words list.
    
    Returns:
        No output
    """
    # note that the last position of i is 3rd to the end
    for i in range(len(tokenized_sentence) - 3 + 1):
        # the sliding window starts at position i and contains 3 words
        trigram = tokenized_sentence[i : i + 3]
        print(trigram)

tokenized_sentence = ['i', 'am', 'happy', 'because', 'i', 'am', 'learning', '.']

print(f'List all trigrams of sentence: {tokenized_sentence}\n')
sentence_to_trigram(tokenized_sentence)

# when working with trigrams, you need to prepend 2 <s> and append one </s>
n = 3
tokenized_sentence = ['i', 'am', 'happy', 'because', 'i', 'am', 'learning', '.']
tokenized_sentence = ["<s>"] * (n - 1) + tokenized_sentence + ["</s>"]
print(tokenized_sentence)

##### NLP Language Models ####
Steps:

-Count matrix
-Probability matrix
-Language model
-Log probability to avoid underflow
-Generative language model


    - in Count Matrix rows correspond to first word on bi Gram, column corresponds to 2nd word on bi gram
    -Sum of a row is all words that starts with a given start of bigram, so if we divide each cell of a row by its rowsum we get the bigram probability
    - to get proabability of a sentense multiply all the probability using prob matrix of each bigram
    
     eg: <s> I Like Cat </s>

     probability of above sentense using bi gram= P(I/<s>)*P(Like/I)*P(Cat/like)*P(</s>/Cat)

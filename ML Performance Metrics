Recall will try to capture as much as true class from the dataset( needed for Anomalies)
Increasing Recall comes at a cost of high False Positives in the output.

from sklearn import metrics

Actuals=[1,0,1,0,1,1,1,0,1,0,0,1]
Pred=[0.1,0.1,0.9,0.1,0.01,1,0,1,1,0,0.8,0.7]
Pred_Thresh= [ 1 if val>0.5 else 0 for val in Pred]

Acc=metrics.accuracy_score(Actuals,Pred_Thresh)
Recall=metrics.recall_score(Actuals,Pred_Thresh)
Precision=metrics.precision_score(Actuals,Pred_Thresh)
Confusion_Metrics=metrics.confusion_matrix(Actuals,Pred_Thresh)
#or
pd.crosstab(Actuals,Pred_Thresh, rownames=['Actuals'],colnames=['Predicted'])
AUC=(metrics.roc_auc_score(Actuals,Pred))

print(f"Accurace={Acc}")
print(f"Recall = {Recall}")
print(f"Precision= {Precision}")
print(f"Confusion Mertics= {Confusion_Metrics}")
print(f"ROC AUC Score={AUC}")
